{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"activation_test.ipynb","provenance":[],"collapsed_sections":["wthyyFOHRUDu"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"a-Q23gJinGse","colab_type":"code","colab":{}},"source":["%load_ext tensorboard\n","%tensorboard --logdir logs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G72QYkBOoB6H","colab_type":"code","colab":{}},"source":["!pip uninstall tensorflow\n","!pip install tensorflow"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IxBypgl6RQew","colab_type":"text"},"source":["###de ai"]},{"cell_type":"code","metadata":{"id":"TBG-K055p5oz","colab_type":"code","colab":{}},"source":["# the variables that will be tested\n","activations = [\"linear\", \"elu\", \"relu\", \"selu\", \"tanh\", \"softmax\", \"softplus\", \"softsign\", \"sigmoid\", \"hard_sigmoid\"]\n","learning_rates = [0.001, 0.0001, 0.01]\n","epochs = [100, 500]\n","\n","\n","import gspread\n","from oauth2client.service_account import ServiceAccountCredentials\n","\n","scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n","creds = ServiceAccountCredentials.from_json_keyfile_name('AIOptiver-8fe80fafc591.json', scope)\n","# connect to spreadsheet\n","client = gspread.authorize(creds)\n","\n","main_sheet = client.open('activation').worksheet(\"main\") # open the sheet where the data will be stored\n","\n","\n","for z in epochs:\n","  for y in learning_rates:\n","    for x in activations: # loop over every possibility\n","      index = 0\n","      if (y == 0.0001): #place to store the variables in spreadsheet\n","        index += 11\n","      elif (y == 0.01):\n","        index += 22\n","      if (z == 500):\n","        index += 33\n","      \n","      if (main_sheet.cell(index + activations.index(x)+2, 5).value == ''):\n","        print(x)\n","        # train the AI with variables and retrieve output\n","        a, b, c, d, history, model = TrainAI(x, y, z, \"mean_squared_error\")\n","        print(f\"FirstLoss: {a}, LastLoss: {b}, FirstMAE: {c}, LastMAE: {d}, Activation: {x}, Learning_rate; {y}, epochs: {z}\")\n","\n","\n","        # store output in spreadsheet\n","        try: # to catch errors so that the training will continue\n","          main_sheet.update_cell(index + activations.index(x)+2, 5, a)\n","          main_sheet.update_cell(index + activations.index(x)+2, 6, b)\n","          main_sheet.update_cell(index + activations.index(x)+2, 7, float(c))\n","          main_sheet.update_cell(index + activations.index(x)+2, 8, float(d))\n","        except:\n","          ...\n","\n","\n","        #####################################################################\n","        # create graph which shows training proces\n","        import matplotlib.pyplot as plt\n","        fig = plt.figure(figsize=(3,6))\n","\n","        fig, ax1 = plt.subplots()\n","        plt.title(f'Training using: {x}, learning_rate={y}')\n","        # do things\n","        color = 'tab:red'\n","        ax1.set_xlabel('Epochs')\n","        ax1.set_ylabel('MAE', color=color)\n","        ax1.plot(history.history['mean_absolute_error'], color=color, label=\"MAE\")\n","        ax1.tick_params(axis='y', labelcolor=color)\n","        ax1.set_ylim([0, 10000])\n","        ax2 = ax1.twinx()\n","\n","        color = 'tab:blue'\n","        ax2.set_ylabel('Loss', color=color\n","        ax2.plot(history.history['loss'], color=color, label=\"Loss\")\n","        ax2.tick_params(axis='y', labelcolor=color)\n","\n","        fig.legend(loc='upper right', bbox_to_anchor=(0.865, 0.9), title=\"Legend\")\n","        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","        \n","        plt.savefig(f\"graphs/training/{z}/plot_{x}_learning{str(y).split('.')[-1]}\", format=\"png\", dpi=fig.dpi) # save image\n","        plt.show()\n","\n","\n","        #####################################################################\n","        # predict look_ahead points (based on dataset)\n","\n","        import numpy as np\n","        testdata = np.load(\"npy/testdata_100_10.npy\") # open test file\n","        print(testdata.shape)\n","\n","        # open scaler\n","        from sklearn.externals import joblib\n","        scaler_filename = \"scaler.save\"\n","        scaler = joblib.load(scaler_filename) \n","\n","        testdata[0,0] = scaler.transform(np.array([testdata[0,0]]))\n","        print(testdata.shape)\n","\n","        look_ahead = 10\n","        amount_of_points = 100\n","        batch_size = 1\n","        trainPredict = np.array([testdata[0][0:,0:amount_of_points]])\n","        predictions = np.zeros((look_ahead))\n","        print(trainPredict.shape)\n","        for i in range(look_ahead): # predict 10 points\n","            prediction = model.predict(np.array([trainPredict[0][0:,0:]]), batch_size=batch_size)\n","            print(prediction)\n","            predictions[i] = prediction[0] # store prediction\n","            trainPredict = np.array([testdata[0][0:,i:amount_of_points+i]]) # set input data\n","\n","        # make a graph of the predictions\n","        import matplotlib.pyplot as plt\n","        plt.figure(figsize=(12,6)) # initiate graph\n","        plt.plot(np.arange(look_ahead),predictions,'r', label=\"prediction traffic\")\n","        plt.plot(np.arange(look_ahead),np.load(\"npy/testdata_100_10.npy\")[0][0, -look_ahead-1:-1], label=\"validation traffic\")\n","        plt.xlabel(\"time_stamps\")\n","        plt.ylabel(\"network_load (Mbps)\")\n","        plt.title(f'Prediction using: {x}, learning_rate={y}')\n","        plt.legend()\n","        plt.savefig(f\"graphs/predictions/{z}/plot_{x}_learning{str(y).split('.')[-1]}_prediction\", format=\"png\", dpi=fig.dpi) # save image\n","        plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uF_jBqnkcFTd","colab_type":"code","colab":{}},"source":["def TrainAI(activation, learning, epochs, loss):\n","  # \n","  import tensorflow as tf\n","\n","  from google.colab import output\n","  from tensorflow.keras.models import Sequential\n","  from tensorflow.keras.layers import Dense\n","  from tensorflow.keras.layers import Dropout\n","  from tensorflow.keras.layers import Reshape\n","  from tensorflow.keras.layers import LSTM\n","  import numpy as np\n","\n","\n","  trainX = np.load(\"npy/newdata.npy\")\n","  trainY = np.load(\"npy/newdataoutput.npy\")\n","\n","  trainY = np.reshape(trainY[0], (64,1))\n","  batch_size = 1\n","  amount_of_points = 100\n","\n","\n","  from sklearn.externals import joblib\n","  scaler_filename = \"scaler.save\"\n","  scaler = joblib.load(scaler_filename) \n","\n","  trainX[0:,0] = scaler.transform(trainX[0:,0])\n","\n","\n","  model = Sequential()\n","\n","  model.add(LSTM(64, input_shape=(2, amount_of_points), return_sequences=True, activation=activation)) # add first layer\n","  model.add(LSTM(32, activation=activation)) # add second layer\n","\n","  model.add(Dense(1, activation=activation)) # add last layer\n","\n","  optimizer = tf.keras.optimizers.Adam(learning_rate=learning) # define optimizer\n","  model.compile(loss=loss, optimizer=optimizer, metrics=[\"mae\"]) # compile model\n","\n","\n","  model.summary()\n","\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n","\n","  import time\n","  start_time = time.time()\n","  history = model.fit(np.array(trainX), np.array(trainY), epochs=epochs, batch_size=batch_size, verbose=2, shuffle=False, callbacks=[tensorboard_callback]) # train AI\n","  # output.clear()\n","  print(\"--- fitting model took {} seconds / {} minutes ---\".format(int(time.time()-start_time), round((time.time()-start_time)/60, 2))) # print the time it took to execute\n","  return (history.history['loss'][0], history.history['loss'][-1], history.history['mean_absolute_error'][0], history.history['mean_absolute_error'][-1], history, model)\n","\n"],"execution_count":0,"outputs":[]}]}